{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jTaByi7x2kl1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "from torchvision.models import ResNet50_Weights\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0uKysi9ioe8g"
      },
      "outputs": [],
      "source": [
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWVKcpYK20YU",
        "outputId": "5e0334b7-e4d9-41fb-c07f-903e628cc183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uzTQ-J3H21_e"
      },
      "outputs": [],
      "source": [
        "# Assuming this is the path in your Google Drive\n",
        "dataset_path = '/content/drive/MyDrive/Rice leaf/Rice Leaf Disease Images/'\n",
        "# dataset_path = '/content/drive/MyDrive//Rice leaf/small/'\n",
        "\n",
        "\n",
        "# Image transformations for training with data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Image transformations for validation\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Loading datasets\n",
        "train_dataset = datasets.ImageFolder(root=dataset_path, transform=transform_train)\n",
        "val_dataset = datasets.ImageFolder(root=dataset_path, transform=transform_val)\n",
        "\n",
        "# Splitting datasets\n",
        "validation_split = 0.2\n",
        "shuffle_dataset = True\n",
        "random_seed = 42\n",
        "\n",
        "# Creating data indices for training and validation splits\n",
        "dataset_size = len(train_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "if shuffle_dataset:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]\n",
        "\n",
        "# Creating data samplers and loaders\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, sampler=train_sampler)\n",
        "validation_loader = DataLoader(train_dataset, batch_size=128, sampler=valid_sampler)\n",
        "\n",
        "\n",
        "num_classes = 4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahrCcaBjnpdp"
      },
      "outputs": [],
      "source": [
        "#VGG\n",
        "model = models.vgg16(pretrained=True)\n",
        "model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#resnet\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=num_classes, bias=True)\n"
      ],
      "metadata": {
        "id": "VUURP_2Lf9x9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
        "pretrained = True\n",
        "\n",
        "model = convnext_base(weights=ConvNeXt_Base_Weights.DEFAULT if pretrained else None)\n",
        "model.classifier[2] = nn.Linear(in_features=model.classifier[2].in_features, out_features=num_classes, bias=True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "zvU5yLkhkQCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "UU7D16Qvgyz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FnsAUYfPLyYD"
      },
      "outputs": [],
      "source": [
        "def train_and_validate(model, train_loader, validation_loader, num_epochs=10, patience=3):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    accuracies = []\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        batch_count = 0\n",
        "        print(f\"Epoch {epoch+1} started...\")\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            batch_count += 1\n",
        "\n",
        "\n",
        "        scheduler.step()  # Adjust learning rate\n",
        "        val_loss = validate(model, validation_loader, criterion, device)\n",
        "        accuracy = np.mean(np.array(all_labels) == np.array(all_preds))\n",
        "        train_losses.append(running_loss / len(train_loader.dataset))\n",
        "        val_losses.append(val_loss)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader.dataset):.4f}, Validation Loss: {val_loss:.4f},Accuracy: {accuracy:.4f}')\n",
        "        # print(\"Model saved as best_model.pth\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "            torch.save(model.state_dict(), 'model.pth')\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve == patience:\n",
        "                print(\"Early stopping triggered\")\n",
        "                break\n",
        "    # Plotting training and validation losses\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title('Loss over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plotting accuracies\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(accuracies, label='Accuracy')\n",
        "    plt.title('Accuracy over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_sptFXQ6gsjE"
      },
      "outputs": [],
      "source": [
        "# Validation\n",
        "def validate(model, validation_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    return val_loss / len(validation_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx1YWBVXahMJ",
        "outputId": "551376f0-aa20-4662-a3bb-cc48a3f42e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 4762\n",
            "Total validation samples: 1190\n",
            "Batch size: 128\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total training samples: {len(train_indices)}\")\n",
        "print(f\"Total validation samples: {len(val_indices)}\")\n",
        "print(f\"Batch size: {train_loader.batch_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hh3rBd_g2-0u",
        "outputId": "a68d432a-644f-4ac0-a779-08a6941a1c81"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Epoch 1 started...\n",
            "Epoch 1, Training Loss: 0.1677, Validation Loss: 0.0003,Accuracy: 0.9332\n",
            "Epoch 2 started...\n",
            "Epoch 2, Training Loss: 0.0020, Validation Loss: 0.0002,Accuracy: 1.0000\n",
            "Epoch 3 started...\n"
          ]
        }
      ],
      "source": [
        "# Train and validate model VGG\n",
        "train_and_validate(model, train_loader, validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mm6IeTXhcFD5"
      },
      "outputs": [],
      "source": [
        "train_and_validate(model, train_loader, validation_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYrABR6InNAA"
      },
      "outputs": [],
      "source": [
        "#check if transformed"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}